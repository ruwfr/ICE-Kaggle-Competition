{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-27T05:02:18.110470Z","iopub.status.busy":"2023-11-27T05:02:18.109937Z","iopub.status.idle":"2023-11-27T05:02:18.132224Z","shell.execute_reply":"2023-11-27T05:02:18.130837Z","shell.execute_reply.started":"2023-11-27T05:02:18.110424Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import regex as re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from xgboost import XGBClassifier\n","from imblearn.under_sampling import RandomUnderSampler\n","import random\n","from sklearn.metrics import roc_auc_score\n","from transformers import RobertaModel, RobertaTokenizer\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"markdown","metadata":{},"source":["## Submission Flag"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.132784Z","iopub.status.idle":"2023-11-27T05:02:18.133100Z","shell.execute_reply":"2023-11-27T05:02:18.132967Z","shell.execute_reply.started":"2023-11-27T05:02:18.132951Z"},"trusted":true},"outputs":[],"source":["is_submission = False"]},{"cell_type":"markdown","metadata":{},"source":["## Read Datasets"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.134286Z","iopub.status.idle":"2023-11-27T05:02:18.134626Z","shell.execute_reply":"2023-11-27T05:02:18.134478Z","shell.execute_reply.started":"2023-11-27T05:02:18.134461Z"},"trusted":true},"outputs":[],"source":["train_path1 = r\"data\\train_v2_drcat_02.csv\" if not is_submission else r\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\"\n","train_path2 = r\"data\\train_essays.csv\" if not is_submission else r\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\"\n","test_path = r\"data\\test_essays.csv\" if not is_submission else r\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\"\n","train_data1 = pd.read_csv(train_path1)\n","train_data1.rename(columns={'label': 'generated'}, inplace=True)\n","train_data2 = pd.read_csv(train_path2)\n","test_data = pd.read_csv(test_path)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.135608Z","iopub.status.idle":"2023-11-27T05:02:18.135935Z","shell.execute_reply":"2023-11-27T05:02:18.135779Z","shell.execute_reply.started":"2023-11-27T05:02:18.135762Z"},"trusted":true},"outputs":[{"data":{"text/plain":["generated\n","0    28746\n","1    17500\n","Name: count, dtype: int64"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.concat([train_data1[['text','generated']], train_data2[['text','generated']]])\n","train['text'] = train['text'].str.replace('\\n', '')\n","test_data['text'] = test_data['text'].str.replace('\\n', '')\n","train['generated'].value_counts()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.136806Z","iopub.status.idle":"2023-11-27T05:02:18.137109Z","shell.execute_reply":"2023-11-27T05:02:18.136983Z","shell.execute_reply.started":"2023-11-27T05:02:18.136968Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0:  17500\n","1:  17500\n"]}],"source":["rus = RandomUnderSampler(random_state=42)\n","train_text, train_label = rus.fit_resample(train['text'].to_numpy().reshape(-1,1), train['generated'].to_numpy().reshape(-1,1))\n","print('0: ', np.count_nonzero(train_label == 0))\n","print('1: ', np.count_nonzero(train_label == 1))\n","\n","data = {'text': train_text.reshape(-1), 'generated': train_label.reshape(-1)}\n","train_data = pd.DataFrame(data)\n","\n","if not is_submission:\n","    seed=202\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    mask = np.random.rand(len(train_data)) < 0.8\n","    test_data = train_data[~mask]\n","    train_data = train_data[mask]"]},{"cell_type":"markdown","metadata":{},"source":["## Embeddings"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.137781Z","iopub.status.idle":"2023-11-27T05:02:18.138086Z","shell.execute_reply":"2023-11-27T05:02:18.137961Z","shell.execute_reply.started":"2023-11-27T05:02:18.137946Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load pre-trained RoBERTa model and tokenizer\n","model = RobertaModel.from_pretrained('roberta-base')\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","# Tokenize the text in train data\n","tokenized_train_texts = tokenizer(train_data['text'].to_list(), padding=True, truncation=True, return_tensors='pt')\n","\n","# Tokenize the text in train data\n","tokenized_test_texts = tokenizer(test_data['text'].to_list(), padding=True, truncation=True, return_tensors='pt')\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.139024Z","iopub.status.idle":"2023-11-27T05:02:18.139333Z","shell.execute_reply":"2023-11-27T05:02:18.139182Z","shell.execute_reply.started":"2023-11-27T05:02:18.139167Z"},"trusted":true},"outputs":[],"source":["## Create Dataloader\n","# Convert train labels to tensor\n","train_labels_tensor = torch.tensor(train_data['generated'].values)\n","\n","# Create a train TensorDataset\n","train_dataset = TensorDataset(\n","    tokenized_train_texts['input_ids'],\n","    tokenized_train_texts['attention_mask'],\n","    train_labels_tensor\n",")\n","\n","if is_submission:\n","\n","    # Create a test TensorDataset\n","    test_dataset = TensorDataset(\n","        tokenized_test_texts['input_ids'],\n","        tokenized_test_texts['attention_mask']\n","    )\n","\n","else:\n","    # Convert text labels to tensor\n","    test_labels_tensor = torch.tensor(test_data['generated'].values)\n","\n","    # Create a test TensorDataset\n","    test_dataset = TensorDataset(\n","        tokenized_test_texts['input_ids'],\n","        tokenized_test_texts['attention_mask'],\n","        test_labels_tensor\n","    )\n","\n","# Define batch size\n","batch_size = 16  # You can adjust this based on your system's memory capacity\n","\n","# Create a DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.140611Z","iopub.status.idle":"2023-11-27T05:02:18.140954Z","shell.execute_reply":"2023-11-27T05:02:18.140784Z","shell.execute_reply.started":"2023-11-27T05:02:18.140767Z"},"trusted":true},"outputs":[],"source":["def extract_features(concrete_data_loader):\n","    features_list = []\n","    labels_list = []\n","\n","    with torch.no_grad():\n","        for batch in concrete_data_loader:\n","            batch_tokenized_texts = {\n","                'input_ids': batch[0],\n","                'attention_mask': batch[1]\n","            }\n","            \n","            # Extract token embeddings for the batch\n","            batch_outputs = model(**batch_tokenized_texts)\n","            batch_embeddings = batch_outputs.last_hidden_state\n","            \n","            # Flatten the embeddings to use as features for the batch\n","            batch_features = batch_embeddings.mean(dim=1).numpy()\n","            features_list.append(batch_features)\n","            \n","            # Get labels for the batch\n","            batch_labels = batch[2].numpy()\n","            labels_list.append(batch_labels)\n","    \n","    # Concatenate features from all batches\n","    return np.concatenate(features_list, axis=0), np.concatenate(labels_list, axis=0)\n","\n","def extract_features_test_submission(concrete_data_loader):\n","    features_list = []\n","\n","    with torch.no_grad():\n","        for batch in concrete_data_loader:\n","            batch_tokenized_texts = {\n","                'input_ids': batch[0],\n","                'attention_mask': batch[1]\n","            }\n","            \n","            # Extract token embeddings for the batch\n","            batch_outputs = model(**batch_tokenized_texts)\n","            batch_embeddings = batch_outputs.last_hidden_state\n","            \n","            # Flatten the embeddings to use as features for the batch\n","            batch_features = batch_embeddings.mean(dim=1).numpy()\n","            features_list.append(batch_features)\n","            \n","    \n","    # Concatenate features from all batches\n","    return np.concatenate(features_list, axis=0)\n","\n","# Extract features using DataLoader\n","if is_submission:\n","    train_features, train_labels = extract_features(train_loader)\n","    test_features = extract_features_test_submission(tokenized_test_texts)\n","    print('Len train_features: ', len(train_features), ' Len train_labels: ', len(train_labels))\n","    print('Len train_features: ', len(test_features))\n","else: \n","    train_features, train_labels = extract_features(train_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Len train_features:  27983  Len train_labels:  27983\n","Len train_features:  7017  Len train_labels:  7017\n"]}],"source":["test_features, test_labels = extract_features(test_loader)\n","print('Len train_features: ', len(train_features), ' Len train_labels: ', len(train_labels))\n","print('Len train_features: ', len(test_features), ' Len train_labels: ', len(test_labels))"]},{"cell_type":"markdown","metadata":{},"source":["## Create Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-27T05:02:18.206951Z","iopub.status.busy":"2023-11-27T05:02:18.206694Z","iopub.status.idle":"2023-11-27T05:02:18.225832Z","shell.execute_reply":"2023-11-27T05:02:18.224556Z","shell.execute_reply.started":"2023-11-27T05:02:18.206924Z"},"trusted":true},"outputs":[],"source":["classifier = XGBClassifier(objective = 'binary:logistic', n_estimators = 100, n_jobs = -1)"]},{"cell_type":"markdown","metadata":{},"source":["## Fit Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.226407Z","iopub.status.idle":"2023-11-27T05:02:18.226705Z","shell.execute_reply":"2023-11-27T05:02:18.226574Z","shell.execute_reply.started":"2023-11-27T05:02:18.226559Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=100, n_jobs=-1,\n","              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=100, n_jobs=-1,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"],"text/plain":["XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=100, n_jobs=-1,\n","              num_parallel_tree=None, random_state=None, ...)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["classifier.fit(train_features, train_data.generated)"]},{"cell_type":"markdown","metadata":{},"source":["## Predict Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.228005Z","iopub.status.idle":"2023-11-27T05:02:18.228313Z","shell.execute_reply":"2023-11-27T05:02:18.228175Z","shell.execute_reply.started":"2023-11-27T05:02:18.228158Z"},"trusted":true},"outputs":[],"source":["predictions = classifier.predict_proba(test_features)[:,1]"]},{"cell_type":"markdown","metadata":{},"source":["## Performance and Create Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:02:18.229309Z","iopub.status.idle":"2023-11-27T05:02:18.229621Z","shell.execute_reply":"2023-11-27T05:02:18.229476Z","shell.execute_reply.started":"2023-11-27T05:02:18.229460Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ROC AUC train: 0.9930497268286299\n","ROC AUC val: 0.5104081652548534\n"]}],"source":["if not is_submission:\n","    preds_train = classifier.predict_proba(train_features)[:,1]\n","    preds_val = classifier.predict_proba(test_features)[:,1]\n","    print('ROC AUC train:', roc_auc_score(train_data.generated, preds_train))\n","    print('ROC AUC val:', roc_auc_score(test_data.generated, preds_val))\n","else:\n","    submission = pd.DataFrame({'id':test_data[\"id\"], 'generated':predictions})\n","    submission_path = r\"/kaggle/working/submission.csv\"\n","    submission.to_csv(submission_path, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6888007,"sourceId":61542,"sourceType":"competition"},{"datasetId":4005256,"sourceId":6977472,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
