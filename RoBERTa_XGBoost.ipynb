{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_submission = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path1 = r\"data\\train_v2_drcat_02.csv\" if not is_submission else r\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\"\n",
    "train_path2 = r\"data\\train_essays.csv\" if not is_submission else r\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\"\n",
    "test_path = r\"data\\test_essays.csv\" if not is_submission else r\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\"\n",
    "train_data1 = pd.read_csv(train_path1)\n",
    "train_data1.rename(columns={'label': 'generated'}, inplace=True)\n",
    "train_data2 = pd.read_csv(train_path2)\n",
    "test_data = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_data1[['text','generated']], train_data2[['text','generated']]])\n",
    "train['text'] = train['text'].str.replace('\\n', '')\n",
    "test_data['text'] = test_data['text'].str.replace('\\n', '')\n",
    "train['generated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "train_text, train_label = rus.fit_resample(train['text'].to_numpy().reshape(-1,1), train['generated'].to_numpy().reshape(-1,1))\n",
    "print('0: ', np.count_nonzero(train_label == 0))\n",
    "print('1: ', np.count_nonzero(train_label == 1))\n",
    "\n",
    "data = {'text': train_text.reshape(-1), 'generated': train_label.reshape(-1)}\n",
    "train_data = pd.DataFrame(data)\n",
    "\n",
    "if not is_submission:\n",
    "    seed=202\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    mask = np.random.rand(len(train_data)) < 0.8\n",
    "    test_data = train_data[~mask]\n",
    "    train_data = train_data[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained RoBERTa model and tokenizer\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize the text in train data\n",
    "tokenized_train_texts = tokenizer(train_data['text'].to_list(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Tokenize the text in train data\n",
    "tokenized_test_texts = tokenizer(test_data['text'].to_list(), padding=True, truncation=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Dataloader\n",
    "# Convert train labels to tensor\n",
    "train_labels_tensor = torch.tensor(train_data['generated'].values)\n",
    "\n",
    "# Create a train TensorDataset\n",
    "train_dataset = TensorDataset(\n",
    "    tokenized_train_texts['input_ids'],\n",
    "    tokenized_train_texts['attention_mask'],\n",
    "    train_labels_tensor\n",
    ")\n",
    "\n",
    "# Convert text labels to tensor\n",
    "test_labels_tensor = torch.tensor(test_data['generated'].values)\n",
    "\n",
    "# Create a test TensorDataset\n",
    "test_dataset = TensorDataset(\n",
    "    tokenized_test_texts['input_ids'],\n",
    "    tokenized_test_texts['attention_mask'],\n",
    "    test_labels_tensor\n",
    ")\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16  # You can adjust this based on your system's memory capacity\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(concrete_data_loader):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in concrete_data_loader:\n",
    "            batch_tokenized_texts = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1]\n",
    "            }\n",
    "            \n",
    "            # Extract token embeddings for the batch\n",
    "            batch_outputs = model(**batch_tokenized_texts)\n",
    "            batch_embeddings = batch_outputs.last_hidden_state\n",
    "            \n",
    "            # Flatten the embeddings to use as features for the batch\n",
    "            batch_features = batch_embeddings.mean(dim=1).numpy()\n",
    "            features_list.append(batch_features)\n",
    "            \n",
    "            # Get labels for the batch\n",
    "            batch_labels = batch[2].numpy()\n",
    "            labels_list.append(batch_labels)\n",
    "    \n",
    "    # Concatenate features from all batches\n",
    "    return np.concatenate(features_list, axis=0), np.concatenate(labels_list, axis=0)\n",
    "\n",
    "# Extract features using DataLoader\n",
    "train_features, train_labels = extract_features(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = extract_features(test_loader)\n",
    "print('Len train_features: ', len(train_features), ' Len train_labels: ', len(train_labels))\n",
    "print('Len train_features: ', len(test_features), ' Len train_labels: ', len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(objective = 'binary:logistic', n_estimators = 100, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict_proba(test_features)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance and Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_submission:\n",
    "    preds_train = classifier.predict_proba(train_features)[:,1]\n",
    "    preds_val = classifier.predict_proba(test_features)[:,1]\n",
    "    print('ROC AUC train:', roc_auc_score(train_labels, preds_train))\n",
    "    print('ROC AUC val:', roc_auc_score(test_labels, preds_val))\n",
    "else:\n",
    "    submission = pd.DataFrame({'id':test_data[\"id\"], 'generated':predictions})\n",
    "    submission_path = r\"/kaggle/working/submission.csv\"\n",
    "    submission.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
